{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PURE PYTHON AND PROFILING"
      ],
      "metadata": {
        "id": "SJCVAUC9sd6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time # For profiling\n",
        "\n",
        "# --- Toy Model Dimensions (same as before) ---\n",
        "LATENT_DIM = 4\n",
        "N_MELS = 2\n",
        "FIXED_FRAMES = 4\n",
        "INITIAL_FRAMES = FIXED_FRAMES // 4\n",
        "INITIAL_CHANNELS = 4\n",
        "CONV1_OUT_CHANNELS = 2\n",
        "CONV2_OUT_CHANNELS = 1\n",
        "\n",
        "# --- Helper Functions / Basic Layers (structure same as before) ---\n",
        "# SimpleLinear, SimpleReLU, SimpleUpsampleNearest1D, SimpleConv1d\n",
        "# (Their internal logic remains the same, no timing code inside them for now\n",
        "# to keep them clean. Timing will be done around their calls.)\n",
        "\n",
        "class SimpleLinear:\n",
        "    def __init__(self, input_dim, output_dim, fixed_weights=None, fixed_bias=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        if fixed_weights:\n",
        "            if len(fixed_weights) != output_dim or len(fixed_weights[0]) != input_dim:\n",
        "                raise ValueError(f\"Fixed weights shape mismatch for Linear. Expected ({output_dim}x{input_dim}), got ({len(fixed_weights)}x{len(fixed_weights[0]) if fixed_weights else 0})\")\n",
        "            self.weights = fixed_weights\n",
        "        else:\n",
        "            self.weights = [[(0.01 * (r*input_dim + c + 1)) for c in range(input_dim)] for r in range(output_dim)]\n",
        "        if fixed_bias:\n",
        "            if len(fixed_bias) != output_dim:\n",
        "                raise ValueError(f\"Fixed bias shape mismatch for Linear. Expected ({output_dim}), got ({len(fixed_bias)})\")\n",
        "            self.bias = fixed_bias\n",
        "        else:\n",
        "            self.bias = [(0.01 * (i + 1)) for i in range(output_dim)]\n",
        "\n",
        "    def forward(self, input_vector):\n",
        "        if len(input_vector) != self.input_dim:\n",
        "            raise ValueError(f\"Expected input_vector of dimension {self.input_dim}, got {len(input_vector)}\")\n",
        "        output_vector = [b for b in self.bias]\n",
        "        for i in range(self.output_dim):\n",
        "            for j in range(self.input_dim):\n",
        "                output_vector[i] += self.weights[i][j] * input_vector[j]\n",
        "        return output_vector\n",
        "\n",
        "class SimpleReLU:\n",
        "    def forward(self, input_data):\n",
        "        if isinstance(input_data, (int, float)):\n",
        "            return max(0, input_data)\n",
        "        elif isinstance(input_data, list):\n",
        "            return [self.forward(x) for x in input_data]\n",
        "        else:\n",
        "            raise TypeError(f\"Unsupported type for ReLU: {type(input_data)}\")\n",
        "\n",
        "class SimpleUpsampleNearest1D:\n",
        "    def __init__(self, scale_factor):\n",
        "        self.scale_factor = scale_factor\n",
        "        if not isinstance(scale_factor, int) or scale_factor <= 0:\n",
        "            raise ValueError(\"scale_factor must be a positive integer.\")\n",
        "\n",
        "    def forward(self, input_tensor_channels_frames):\n",
        "        output_tensor = []\n",
        "        if not input_tensor_channels_frames or \\\n",
        "           not isinstance(input_tensor_channels_frames[0], list):\n",
        "            raise ValueError(\"UpsampleNearest1D expects a list of lists (channels x frames).\")\n",
        "        for channel_data in input_tensor_channels_frames:\n",
        "            if not isinstance(channel_data, list):\n",
        "                raise ValueError(\"Each channel in UpsampleNearest1D input must be a list of frames.\")\n",
        "            upsampled_channel = []\n",
        "            for frame_value in channel_data:\n",
        "                upsampled_channel.extend([frame_value] * self.scale_factor)\n",
        "            output_tensor.append(upsampled_channel)\n",
        "        return output_tensor\n",
        "\n",
        "class SimpleConv1d:\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, fixed_kernels=None, fixed_biases=None):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        if fixed_kernels:\n",
        "            if len(fixed_kernels) != out_channels or \\\n",
        "               (in_channels > 0 and (len(fixed_kernels[0]) != in_channels or \\\n",
        "                                     len(fixed_kernels[0][0]) != kernel_size)) or \\\n",
        "               (in_channels == 0 and kernel_size > 0 and fixed_kernels and fixed_kernels[0] and len(fixed_kernels[0]) != 0) :\n",
        "                expected_shape_str = f\"({out_channels}x{in_channels}x{kernel_size})\"\n",
        "                actual_shape_str = f\"({len(fixed_kernels)}x{len(fixed_kernels[0]) if fixed_kernels and len(fixed_kernels)>0 else 'N/A'}x{len(fixed_kernels[0][0]) if fixed_kernels and len(fixed_kernels)>0 and fixed_kernels[0] and len(fixed_kernels[0])>0 else 'N/A'})\"\n",
        "                raise ValueError(f\"Fixed kernels shape mismatch for Conv1d. Expected {expected_shape_str}, got {actual_shape_str}\")\n",
        "            self.kernels = fixed_kernels\n",
        "        else:\n",
        "            self.kernels = [[[(0.01 * (oc*in_channels*kernel_size + ic*kernel_size + k + 1)) for k in range(kernel_size)]\n",
        "                             for ic in range(in_channels)]\n",
        "                            for oc in range(out_channels)]\n",
        "        if fixed_biases:\n",
        "            if len(fixed_biases) != out_channels:\n",
        "                 raise ValueError(f\"Fixed biases shape mismatch for Conv1d. Expected ({out_channels}), got ({len(fixed_biases)})\")\n",
        "            self.biases = fixed_biases\n",
        "        else:\n",
        "            self.biases = [(0.01 * (i+1)) for i in range(out_channels)]\n",
        "\n",
        "    def forward(self, input_tensor_channels_frames):\n",
        "        if not isinstance(input_tensor_channels_frames, list) or \\\n",
        "            (self.in_channels > 0 and (not input_tensor_channels_frames or not isinstance(input_tensor_channels_frames[0], list))):\n",
        "            raise ValueError(f\"Conv1d input must be a list of lists (channels x frames). Got: {type(input_tensor_channels_frames)}\")\n",
        "\n",
        "        if len(input_tensor_channels_frames) != self.in_channels:\n",
        "            if not (self.in_channels == 0 and len(input_tensor_channels_frames) == 0):\n",
        "                raise ValueError(f\"Expected {self.in_channels} input channels, got {len(input_tensor_channels_frames)}\")\n",
        "        if self.in_channels == 0:\n",
        "            return [[self.biases[oc]] for oc in range(self.out_channels)]\n",
        "\n",
        "        num_frames_in_original = len(input_tensor_channels_frames[0])\n",
        "        padded_input = []\n",
        "        if self.padding > 0:\n",
        "            for channel_data in input_tensor_channels_frames:\n",
        "                padded_channel = [0.0] * self.padding + channel_data + [0.0] * self.padding\n",
        "                padded_input.append(padded_channel)\n",
        "        else:\n",
        "            padded_input = [list(cd) for cd in input_tensor_channels_frames]\n",
        "\n",
        "        num_frames_padded = len(padded_input[0])\n",
        "        if self.kernel_size > num_frames_padded :\n",
        "            num_frames_out = 0\n",
        "        else:\n",
        "            num_frames_out = math.floor((num_frames_padded - self.kernel_size) / self.stride + 1)\n",
        "\n",
        "        if num_frames_out <= 0 :\n",
        "            return [[] for _ in range(self.out_channels)]\n",
        "\n",
        "        output_tensor_outchannels_frames = [[0.0] * num_frames_out for _ in range(self.out_channels)]\n",
        "        for oc in range(self.out_channels):\n",
        "            for f_out_idx in range(num_frames_out):\n",
        "                receptive_field_start = f_out_idx * self.stride\n",
        "                current_sum = self.biases[oc]\n",
        "                for ic in range(self.in_channels):\n",
        "                    for k_idx in range(self.kernel_size):\n",
        "                        input_val_idx = receptive_field_start + k_idx\n",
        "                        current_sum += padded_input[ic][input_val_idx] * self.kernels[oc][ic][k_idx]\n",
        "                output_tensor_outchannels_frames[oc][f_out_idx] = current_sum\n",
        "        return output_tensor_outchannels_frames\n",
        "\n",
        "# --- Simplified Decoder with Fixed Weights (and Profiling in forward) ---\n",
        "class SimpleDecoder:\n",
        "    def __init__(self):\n",
        "        self.n_output_channels = N_MELS\n",
        "        self.initial_frames = INITIAL_FRAMES\n",
        "        self.initial_channels = INITIAL_CHANNELS\n",
        "\n",
        "        self.weights_fc = [\n",
        "            [0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8],\n",
        "            [0.2, 0.4, 0.6, 0.8], [0.1, 0.3, 0.5, 0.7]\n",
        "        ]\n",
        "        self.bias_fc = [0.01, 0.02, 0.03, 0.04]\n",
        "        self.fc = SimpleLinear(LATENT_DIM, self.initial_channels * self.initial_frames,\n",
        "                               fixed_weights=self.weights_fc, fixed_bias=self.bias_fc)\n",
        "\n",
        "        self.kernels_conv1 = [\n",
        "            [[0.1, 0.2, 0.1], [0.3, 0.1, 0.2], [0.2, 0.3, 0.1], [0.1, 0.1, 0.3]],\n",
        "            [[0.4, 0.2, 0.1], [0.1, 0.3, 0.4], [0.3, 0.2, 0.2], [0.2, 0.4, 0.1]]\n",
        "        ]\n",
        "        self.biases_conv1 = [0.05, 0.06]\n",
        "\n",
        "        self.kernels_conv2 = [\n",
        "            [[0.5, 0.1, 0.2], [0.2, 0.3, 0.5]]\n",
        "        ]\n",
        "        self.biases_conv2 = [0.07]\n",
        "\n",
        "        self.kernels_conv3 = [ [[0.8]], [[0.9]] ]\n",
        "        self.biases_conv3 = [0.08, 0.09]\n",
        "\n",
        "        self.decode_layer_configs = [ # Store type and specific layer for targeted profiling\n",
        "            (SimpleReLU, SimpleReLU()),\n",
        "            (SimpleUpsampleNearest1D, SimpleUpsampleNearest1D(scale_factor=2)),\n",
        "            (SimpleConv1d, SimpleConv1d(self.initial_channels, CONV1_OUT_CHANNELS, kernel_size=3, stride=1, padding=1,\n",
        "                                        fixed_kernels=self.kernels_conv1, fixed_biases=self.biases_conv1), \"Conv1\"),\n",
        "            (SimpleReLU, SimpleReLU()),\n",
        "            (SimpleUpsampleNearest1D, SimpleUpsampleNearest1D(scale_factor=2)),\n",
        "            (SimpleConv1d, SimpleConv1d(CONV1_OUT_CHANNELS, CONV2_OUT_CHANNELS, kernel_size=3, stride=1, padding=1,\n",
        "                                        fixed_kernels=self.kernels_conv2, fixed_biases=self.biases_conv2), \"Conv2\"),\n",
        "            (SimpleReLU, SimpleReLU()),\n",
        "            (SimpleConv1d, SimpleConv1d(CONV2_OUT_CHANNELS, self.n_output_channels, kernel_size=1, stride=1, padding=0,\n",
        "                                        fixed_kernels=self.kernels_conv3, fixed_biases=self.biases_conv3), \"Conv3_Output\"),\n",
        "            (SimpleReLU, SimpleReLU())\n",
        "        ]\n",
        "        # self.decode_layers is just the list of layer instances\n",
        "        self.decode_layers = [lc[1] for lc in self.decode_layer_configs]\n",
        "\n",
        "\n",
        "    def reshape_to_channels_frames(self, flat_list, channels, frames):\n",
        "        if len(flat_list) != channels * frames:\n",
        "            raise ValueError(f\"Cannot reshape list of size {len(flat_list)} into ({channels}, {frames})\")\n",
        "        reshaped = []\n",
        "        for i in range(channels):\n",
        "            reshaped.append(flat_list[i * frames : (i + 1) * frames])\n",
        "        return reshaped\n",
        "\n",
        "    def forward(self, z, verbose=False, collect_timings=False):\n",
        "        timings = {} # To store timings for different parts\n",
        "\n",
        "        # --- FC Layer ---\n",
        "        if collect_timings: t_start = time.perf_counter()\n",
        "        x = self.fc.forward(z)\n",
        "        if collect_timings: timings['fc'] = time.perf_counter() - t_start\n",
        "        if verbose: print(f\"After FC: {x}\")\n",
        "\n",
        "        # --- Reshape ---\n",
        "        if collect_timings: t_start = time.perf_counter()\n",
        "        x = self.reshape_to_channels_frames(x, self.initial_channels, self.initial_frames)\n",
        "        if collect_timings: timings['reshape'] = time.perf_counter() - t_start\n",
        "        if verbose: print(f\"After Reshape: {x}\")\n",
        "\n",
        "        # --- Decode Layers ---\n",
        "        # Initialize cumulative timings for layer types\n",
        "        if collect_timings:\n",
        "            timings['relu_total'] = 0\n",
        "            timings['upsample_total'] = 0\n",
        "            # Individual conv timings will be stored by their given names\n",
        "            # (e.g., timings['Conv1'], timings['Conv2'])\n",
        "\n",
        "        for i, (layer_type, layer_instance, *layer_name_tuple) in enumerate(self.decode_layer_configs):\n",
        "            layer_display_name = layer_name_tuple[0] if layer_name_tuple else layer_instance.__class__.__name__ + f\"_{i}\"\n",
        "\n",
        "            if collect_timings: t_layer_start = time.perf_counter()\n",
        "            x = layer_instance.forward(x) # Use the instance from decode_layer_configs\n",
        "            if collect_timings:\n",
        "                layer_time = time.perf_counter() - t_layer_start\n",
        "                if layer_type == SimpleReLU:\n",
        "                    timings['relu_total'] += layer_time\n",
        "                elif layer_type == SimpleUpsampleNearest1D:\n",
        "                    timings['upsample_total'] += layer_time\n",
        "                elif layer_type == SimpleConv1d and layer_name_tuple: # Specific named Conv layer\n",
        "                    timings[layer_name_tuple[0]] = layer_time\n",
        "                # else:\n",
        "                #    timings[layer_display_name] = layer_time # Generic timing for other layers if any\n",
        "\n",
        "            if verbose:\n",
        "                num_channels_out = len(x) if isinstance(x, list) and x else 0\n",
        "                num_frames_out = len(x[0]) if num_channels_out > 0 and isinstance(x[0], list) and x[0] else 0\n",
        "                if num_channels_out > 0 and not x[0]: num_frames_out = 0\n",
        "                print(f\"After Layer {i} ({layer_display_name}): Shape=({num_channels_out}x{num_frames_out}), Output={[[round(val, 4) for val in ch] for ch in x]}\")\n",
        "\n",
        "        recon_mel_spec = x\n",
        "        if collect_timings:\n",
        "            return recon_mel_spec, timings\n",
        "        else:\n",
        "            return recon_mel_spec\n",
        "\n",
        "# --- Benchmarking and Example Usage ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Toy Model Decoder with Fixed Weights & Input ---\")\n",
        "    # ... (Dimension printouts remain the same) ...\n",
        "\n",
        "    decoder = SimpleDecoder()\n",
        "    fixed_z = [0.1, 0.5, 0.2, 0.6]\n",
        "    print(f\"\\nFixed Input latent vector z: {fixed_z}\")\n",
        "\n",
        "    # --- Single Verbose Run (for verification) ---\n",
        "    print(\"\\n--- Starting a single verbose forward pass (for verification) ---\")\n",
        "    reconstructed_output_verbose, _ = decoder.forward(fixed_z, verbose=True, collect_timings=True) # also collect timings once\n",
        "    print(\"\\n--- Final Output (from verbose run) ---\")\n",
        "    if reconstructed_output_verbose:\n",
        "        # ... (print output as before) ...\n",
        "        output_channels = len(reconstructed_output_verbose)\n",
        "        output_frames = 0\n",
        "        if output_channels > 0 and isinstance(reconstructed_output_verbose[0], list):\n",
        "             output_frames = len(reconstructed_output_verbose[0])\n",
        "        print(f\"Shape: {output_channels} channels x {output_frames} frames\")\n",
        "        for r_idx, r_channel_data in enumerate(reconstructed_output_verbose):\n",
        "            print(f\"  Channel {r_idx}: {[round(val, 4) for val in r_channel_data]}\")\n",
        "\n",
        "\n",
        "    # --- Benchmarking Runs ---\n",
        "    print(\"\\n--- Starting Benchmarking ---\")\n",
        "    num_benchmark_runs = 100 # Number of times to run the forward pass for averaging\n",
        "\n",
        "    total_forward_time = 0\n",
        "    # To store aggregated timings for each component\n",
        "    aggregated_component_timings = {}\n",
        "\n",
        "    for i in range(num_benchmark_runs):\n",
        "        run_start_time = time.perf_counter()\n",
        "        # For benchmarking, run without verbose, but collect timings\n",
        "        _, component_timings = decoder.forward(fixed_z, verbose=False, collect_timings=True)\n",
        "        run_end_time = time.perf_counter()\n",
        "\n",
        "        total_forward_time += (run_end_time - run_start_time)\n",
        "\n",
        "        for key, value in component_timings.items():\n",
        "            if key not in aggregated_component_timings:\n",
        "                aggregated_component_timings[key] = 0\n",
        "            aggregated_component_timings[key] += value\n",
        "        if (i + 1) % (num_benchmark_runs // 10 if num_benchmark_runs >=10 else 1) == 0:\n",
        "            print(f\"  Completed run {i+1}/{num_benchmark_runs}\")\n",
        "\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_forward_time = total_forward_time / num_benchmark_runs\n",
        "    avg_component_timings = {k: v / num_benchmark_runs for k, v in aggregated_component_timings.items()}\n",
        "\n",
        "    print(\"\\n--- Benchmarking Results ---\")\n",
        "    print(f\"Number of benchmark runs: {num_benchmark_runs}\")\n",
        "    print(f\"Average total forward pass time: {avg_forward_time:.8f} seconds\")\n",
        "\n",
        "    print(\"\\nAverage time per component:\")\n",
        "    # Sort for consistent output order\n",
        "    sorted_components = sorted(avg_component_timings.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    for component, avg_time in sorted_components:\n",
        "        percentage_of_total = (avg_time / avg_forward_time) * 100 if avg_forward_time > 0 else 0\n",
        "        print(f\"  - {component:<15}: {avg_time:.8f} seconds ({percentage_of_total:.2f}%)\")\n",
        "\n",
        "    # --- Sanity checks (same as before) ---\n",
        "    assert decoder.decode_layers[5].in_channels == CONV1_OUT_CHANNELS\n",
        "    assert decoder.decode_layers[5].out_channels == CONV2_OUT_CHANNELS\n",
        "    print(\"\\nDeterministic model setup and profiling complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jna-NPXInNVN",
        "outputId": "a8054a1f-e65a-491f-ca26-4194aeaad284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Toy Model Decoder with Fixed Weights & Input ---\n",
            "\n",
            "Fixed Input latent vector z: [0.1, 0.5, 0.2, 0.6]\n",
            "\n",
            "--- Starting a single verbose forward pass (for verification) ---\n",
            "After FC: [0.42, 0.99, 0.85, 0.72]\n",
            "After Reshape: [[0.42], [0.99], [0.85], [0.72]]\n",
            "After Layer 0 (SimpleReLU_0): Shape=(4x1), Output=[[0.42], [0.99], [0.85], [0.72]]\n",
            "After Layer 1 (SimpleUpsampleNearest1D_1): Shape=(4x2), Output=[[0.42, 0.42], [0.99, 0.99], [0.85, 0.85], [0.72, 0.72]]\n",
            "After Layer 2 (Conv1): Shape=(2x2), Output=[[1.101, 1.141], [1.579, 1.565]]\n",
            "After Layer 3 (SimpleReLU_3): Shape=(2x2), Output=[[1.101, 1.141], [1.579, 1.565]]\n",
            "After Layer 4 (SimpleUpsampleNearest1D_4): Shape=(2x4), Output=[[1.101, 1.101, 1.141, 1.141], [1.579, 1.579, 1.565, 1.565]]\n",
            "After Layer 5 (Conv2): Shape=(1x4), Output=[[1.6635, 2.5308, 2.5306, 1.5371]]\n",
            "After Layer 6 (SimpleReLU_6): Shape=(1x4), Output=[[1.6635, 2.5308, 2.5306, 1.5371]]\n",
            "After Layer 7 (Conv3_Output): Shape=(2x4), Output=[[1.4108, 2.1046, 2.1045, 1.3097], [1.5872, 2.3677, 2.3675, 1.4734]]\n",
            "After Layer 8 (SimpleReLU_8): Shape=(2x4), Output=[[1.4108, 2.1046, 2.1045, 1.3097], [1.5872, 2.3677, 2.3675, 1.4734]]\n",
            "\n",
            "--- Final Output (from verbose run) ---\n",
            "Shape: 2 channels x 4 frames\n",
            "  Channel 0: [1.4108, 2.1046, 2.1045, 1.3097]\n",
            "  Channel 1: [1.5872, 2.3677, 2.3675, 1.4734]\n",
            "\n",
            "--- Starting Benchmarking ---\n",
            "  Completed run 10/100\n",
            "  Completed run 20/100\n",
            "  Completed run 30/100\n",
            "  Completed run 40/100\n",
            "  Completed run 50/100\n",
            "  Completed run 60/100\n",
            "  Completed run 70/100\n",
            "  Completed run 80/100\n",
            "  Completed run 90/100\n",
            "  Completed run 100/100\n",
            "\n",
            "--- Benchmarking Results ---\n",
            "Number of benchmark runs: 100\n",
            "Average total forward pass time: 0.00010528 seconds\n",
            "\n",
            "Average time per component:\n",
            "  - relu_total     : 0.00002664 seconds (25.30%)\n",
            "  - Conv1          : 0.00002303 seconds (21.88%)\n",
            "  - Conv2          : 0.00001329 seconds (12.62%)\n",
            "  - Conv3_Output   : 0.00001148 seconds (10.90%)\n",
            "  - upsample_total : 0.00000659 seconds (6.26%)\n",
            "  - fc             : 0.00000579 seconds (5.50%)\n",
            "  - reshape        : 0.00000204 seconds (1.93%)\n",
            "\n",
            "Deterministic model setup and profiling complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversion To Fixed"
      ],
      "metadata": {
        "id": "VU0stpExtR9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # For round\n",
        "\n",
        "# --- Fixed-Point Parameters ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1 # -1 for the sign bit\n",
        "SCALE = 1 << FRACTIONAL_BITS  # 2**8 = 256\n",
        "\n",
        "# Calculate min and max representable scaled integer values for signed 16-bit\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))  # -32768\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1 #  32767\n",
        "\n",
        "def float_to_sfixed(val_float, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a float to a scaled signed integer for fixed-point representation.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    scaled_val = int(round(val_float * scale_factor))\n",
        "    # Clamp to the defined TOTAL_BITS signed range\n",
        "    clamped_val = max(MIN_SFIXED_VAL, min(MAX_SFIXED_VAL, scaled_val))\n",
        "    return clamped_val\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a scaled signed integer back to a float.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "print(f\"--- Fixed-Point Configuration ---\")\n",
        "print(f\"TOTAL_BITS: {TOTAL_BITS}, FRACTIONAL_BITS: {FRACTIONAL_BITS}, INTEGER_BITS (excluding sign): {INTEGER_BITS}\")\n",
        "print(f\"SCALE: {SCALE}\")\n",
        "print(f\"MIN_SFIXED_VAL (scaled int): {MIN_SFIXED_VAL}\")\n",
        "print(f\"MAX_SFIXED_VAL (scaled int): {MAX_SFIXED_VAL}\")\n",
        "print(f\"Representable float range: {sfixed_to_float(MIN_SFIXED_VAL):.4f} to {sfixed_to_float(MAX_SFIXED_VAL):.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJGtkKwHoFML",
        "outputId": "3bd6dfe4-4b4b-435f-bd0e-980f6c8ea2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fixed-Point Configuration ---\n",
            "TOTAL_BITS: 16, FRACTIONAL_BITS: 8, INTEGER_BITS (excluding sign): 7\n",
            "SCALE: 256\n",
            "MIN_SFIXED_VAL (scaled int): -32768\n",
            "MAX_SFIXED_VAL (scaled int): 32767\n",
            "Representable float range: -128.0000 to 127.9961\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FC GOLDEN OUTPUT"
      ],
      "metadata": {
        "id": "zmUY7XAJ8DI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # For round\n",
        "\n",
        "# --- Fixed-Point Parameters ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1 # -1 for the sign bit\n",
        "SCALE = 1 << FRACTIONAL_BITS  # 2**8 = 256\n",
        "\n",
        "# Calculate min and max representable scaled integer values for signed 16-bit\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))  # -32768\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1 #  32767\n",
        "\n",
        "def float_to_sfixed(val_float, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a float to a scaled signed integer for fixed-point representation.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    scaled_val = int(round(val_float * scale_factor))\n",
        "    # Clamp to the defined TOTAL_BITS signed range\n",
        "    clamped_val = max(MIN_SFIXED_VAL, min(MAX_SFIXED_VAL, scaled_val))\n",
        "    return clamped_val\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a scaled signed integer back to a float.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- Layer Dimensions relevant for FC Layer ---\n",
        "LATENT_DIM = 4\n",
        "# For the FC layer in SimpleDecoder, output_dim = initial_channels * initial_frames\n",
        "INITIAL_CHANNELS = 4\n",
        "INITIAL_FRAMES = 1 # Calculated from FIXED_FRAMES // 4 where FIXED_FRAMES was 4\n",
        "FC_OUTPUT_SIZE = INITIAL_CHANNELS * INITIAL_FRAMES # Should be 4 * 1 = 4\n",
        "\n",
        "# --- Definition of SimpleLinear (needed to compute FC output) ---\n",
        "class SimpleLinear:\n",
        "    def __init__(self, input_dim, output_dim, fixed_weights=None, fixed_bias=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        if fixed_weights:\n",
        "            if len(fixed_weights) != output_dim or len(fixed_weights[0]) != input_dim:\n",
        "                raise ValueError(f\"Fixed weights shape mismatch for Linear. Expected ({output_dim}x{input_dim}), got ({len(fixed_weights)}x{len(fixed_weights[0]) if fixed_weights else 0})\")\n",
        "            self.weights = fixed_weights\n",
        "        else: # Fallback, not used if providing fixed_weights\n",
        "            self.weights = [[0.0 for _ in range(input_dim)] for _ in range(output_dim)]\n",
        "        if fixed_bias:\n",
        "            if len(fixed_bias) != output_dim:\n",
        "                raise ValueError(f\"Fixed bias shape mismatch for Linear. Expected ({output_dim}), got ({len(fixed_bias)})\")\n",
        "            self.bias = fixed_bias\n",
        "        else: # Fallback\n",
        "            self.bias = [0.0 for _ in range(output_dim)]\n",
        "\n",
        "    def forward(self, input_vector):\n",
        "        if len(input_vector) != self.input_dim:\n",
        "            raise ValueError(f\"Expected input_vector of dimension {self.input_dim}, got {len(input_vector)}\")\n",
        "        output_vector = [b for b in self.bias] # Start with bias\n",
        "        for i in range(self.output_dim): # Output dimension\n",
        "            for j in range(self.input_dim): # Input dimension\n",
        "                output_vector[i] += self.weights[i][j] * input_vector[j]\n",
        "        return output_vector\n",
        "\n",
        "# --- Main section to generate and print golden values for FC Layer ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Golden Fixed-Point Values for FC Layer ---\")\n",
        "    print(f\"Fixed-Point Config: TOTAL_BITS={TOTAL_BITS}, FRACTIONAL_BITS={FRACTIONAL_BITS} (S{INTEGER_BITS+1}.{FRACTIONAL_BITS}), SCALE={SCALE}\\n\")\n",
        "\n",
        "    # 1. Define inputs, weights, and biases in float (as in SimpleDecoder)\n",
        "    fixed_z_float = [0.1, 0.5, 0.2, 0.6]\n",
        "\n",
        "    weights_fc_float = [\n",
        "        [0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8],\n",
        "        [0.2, 0.4, 0.6, 0.8], [0.1, 0.3, 0.5, 0.7]\n",
        "    ]\n",
        "    bias_fc_float = [0.01, 0.02, 0.03, 0.04]\n",
        "\n",
        "    # 2. Instantiate the Python model for the FC layer\n",
        "    fc_layer_python_model = SimpleLinear(\n",
        "        input_dim=LATENT_DIM,\n",
        "        output_dim=FC_OUTPUT_SIZE,\n",
        "        fixed_weights=weights_fc_float,\n",
        "        fixed_bias=bias_fc_float\n",
        "    )\n",
        "\n",
        "    # 3. Calculate the output of the FC layer in float\n",
        "    fc_output_float = fc_layer_python_model.forward(fixed_z_float)\n",
        "    # This should match [0.42, 0.99, 0.85, 0.72] from your previous logs\n",
        "\n",
        "    # 4. Convert all these to scaled fixed-point integers and print\n",
        "\n",
        "    # Input z\n",
        "    fixed_z_sfixed = [float_to_sfixed(val) for val in fixed_z_float]\n",
        "    print(\"--- Input z (fixed_z_sfixed) for Verilog DUT ---\")\n",
        "    # E.g., i_z[0] = 16'sd26; // 0.1\n",
        "    for i in range(len(fixed_z_float)):\n",
        "        print(f\"i_z[{i}] = 16'sd{fixed_z_sfixed[i]}; \\t// Float: {fixed_z_float[i]:.2f}\")\n",
        "\n",
        "    # Weights\n",
        "    weights_fc_sfixed = [[float_to_sfixed(val) for val in row] for row in weights_fc_float]\n",
        "    print(\"\\n--- Weights_FC (weights_fc_sfixed) for Verilog parameters/locals ---\")\n",
        "    # E.g. WEIGHTS_FC[0][0] = 16'sd26; // 0.1\n",
        "    print(\"localparam signed [15:0] WEIGHTS_FC [0:3][0:3] = '{\")\n",
        "    for r in range(len(weights_fc_sfixed)):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in weights_fc_sfixed[r]])\n",
        "        print(f\"    '{'{'}{row_sfixed_str}{'}'}{',' if r < len(weights_fc_sfixed)-1 else ''} // Row {r}\")\n",
        "    print(\"};\")\n",
        "\n",
        "    # Biases\n",
        "    bias_fc_sfixed = [float_to_sfixed(val) for val in bias_fc_float]\n",
        "    print(\"\\n--- Biases_FC (bias_fc_sfixed) for Verilog parameters/locals ---\")\n",
        "    # E.g. BIAS_FC[0] = 16'sd3; // 0.01\n",
        "    bias_sfixed_str = \", \".join([f\"16'sd{val}\" for val in bias_fc_sfixed])\n",
        "    print(f\"localparam signed [15:0] BIAS_FC [0:3] = '{{{bias_sfixed_str}}};\")\n",
        "\n",
        "\n",
        "    # Golden Output\n",
        "    fc_output_golden_sfixed = [float_to_sfixed(val) for val in fc_output_float]\n",
        "    print(\"\\n--- Golden FC Output (fc_output_golden_sfixed) for Verilog Testbench Comparison ---\")\n",
        "    # E.g. golden_output[0] = 16'sd108; // 0.42\n",
        "    print(\"logic signed [15:0] golden_fc_output [0:3];\")\n",
        "    print(\"initial begin\")\n",
        "    for i in range(len(fc_output_float)):\n",
        "        print(f\"    golden_fc_output[{i}] = 16'sd{fc_output_golden_sfixed[i]}; \\t// Float: {fc_output_float[i]:.2f}\")\n",
        "    print(\"end\")\n",
        "\n",
        "    print(\"\\n--- Sanity check: FC output float values ---\")\n",
        "    print(f\"Calculated fc_output_float: {fc_output_float}\")\n",
        "    # Expected based on previous full decoder log: [0.42, 0.99, 0.85, 0.72]\n",
        "    # Small differences might occur due to rounding in fixed-point vs full float precision.\n",
        "    # Let's also print the float values from the sfixed golden output to see effect of quantization\n",
        "    fc_output_quantized_float = [sfixed_to_float(val) for val in fc_output_golden_sfixed]\n",
        "    print(f\"FC output from sfixed (quantized): { [round(f,4) for f in fc_output_quantized_float] }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvVKkLb_tXR0",
        "outputId": "6af0891a-6e99-46fc-f926-1e213537467c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Golden Fixed-Point Values for FC Layer ---\n",
            "Fixed-Point Config: TOTAL_BITS=16, FRACTIONAL_BITS=8 (S8.8), SCALE=256\n",
            "\n",
            "--- Input z (fixed_z_sfixed) for Verilog DUT ---\n",
            "i_z[0] = 16'sd26; \t// Float: 0.10\n",
            "i_z[1] = 16'sd128; \t// Float: 0.50\n",
            "i_z[2] = 16'sd51; \t// Float: 0.20\n",
            "i_z[3] = 16'sd154; \t// Float: 0.60\n",
            "\n",
            "--- Weights_FC (weights_fc_sfixed) for Verilog parameters/locals ---\n",
            "localparam signed [15:0] WEIGHTS_FC [0:3][0:3] = '{\n",
            "    '{16'sd26, 16'sd51, 16'sd77, 16'sd102}, // Row 0\n",
            "    '{16'sd128, 16'sd154, 16'sd179, 16'sd205}, // Row 1\n",
            "    '{16'sd51, 16'sd102, 16'sd154, 16'sd205}, // Row 2\n",
            "    '{16'sd26, 16'sd77, 16'sd128, 16'sd179} // Row 3\n",
            "};\n",
            "\n",
            "--- Biases_FC (bias_fc_sfixed) for Verilog parameters/locals ---\n",
            "localparam signed [15:0] BIAS_FC [0:3] = '{16'sd3, 16'sd5, 16'sd8, 16'sd10};\n",
            "\n",
            "--- Golden FC Output (fc_output_golden_sfixed) for Verilog Testbench Comparison ---\n",
            "logic signed [15:0] golden_fc_output [0:3];\n",
            "initial begin\n",
            "    golden_fc_output[0] = 16'sd108; \t// Float: 0.42\n",
            "    golden_fc_output[1] = 16'sd253; \t// Float: 0.99\n",
            "    golden_fc_output[2] = 16'sd218; \t// Float: 0.85\n",
            "    golden_fc_output[3] = 16'sd184; \t// Float: 0.72\n",
            "end\n",
            "\n",
            "--- Sanity check: FC output float values ---\n",
            "Calculated fc_output_float: [0.42, 0.99, 0.85, 0.72]\n",
            "FC output from sfixed (quantized): [0.4219, 0.9883, 0.8516, 0.7188]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RELU GOLDEN OUTPUT"
      ],
      "metadata": {
        "id": "t6W6bJM08M_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # For round\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent with previous stage) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "# For S<I>.<F> format, I = TOTAL_BITS - FRACTIONAL_BITS - 1 (for sign bit)\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS  # 2**8 = 256\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))  # -32768\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1 #  32767\n",
        "\n",
        "# --- Utility functions (not strictly needed for this ReLU example with positive inputs, but good for completeness) ---\n",
        "def float_to_sfixed(val_float, f_bits=FRACTIONAL_BITS, total_bits=TOTAL_BITS):\n",
        "    \"\"\"Converts a float to a scaled signed integer for fixed-point representation.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    min_val = -(1 << (total_bits - 1))\n",
        "    max_val = (1 << (total_bits - 1)) - 1\n",
        "\n",
        "    scaled_val = int(round(val_float * scale_factor))\n",
        "    clamped_val = max(min_val, min(max_val, scaled_val))\n",
        "    return clamped_val\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a scaled signed integer back to a float.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- ReLU Golden Value Generation ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Golden Fixed-Point Values for ReLU Module ---\")\n",
        "    print(f\"Fixed-Point Config: TOTAL_BITS={TOTAL_BITS}, FRACTIONAL_BITS={FRACTIONAL_BITS} (S{INTEGER_BITS+1}.{FRACTIONAL_BITS}), SCALE={SCALE}\\n\")\n",
        "\n",
        "    # 1. Define Inputs for ReLU stage\n",
        "    # These are the *actual fixed-point integer outputs* from the Verilog fc_layer simulation.\n",
        "    # From VCS log: Got_Verilog [108, 254, 218, 186]\n",
        "    relu_input_sfixed = [108, 254, 218, 186]\n",
        "\n",
        "    print(\"--- Input to ReLU Module (relu_input_sfixed) ---\")\n",
        "    print(\"--- (These are the actual outputs from the Verilog fc_layer) ---\")\n",
        "    # E.g., i_data[0] = 16'sd108;\n",
        "    for i in range(len(relu_input_sfixed)):\n",
        "        approx_float = sfixed_to_float(relu_input_sfixed[i])\n",
        "        print(f\"i_data[{i}] = 16'sd{relu_input_sfixed[i]}; \\t// Approx Float: {approx_float:.4f}\")\n",
        "\n",
        "    # 2. Calculate Golden Output for ReLU\n",
        "    # ReLU operation: output = (input < 0) ? 0 : input;\n",
        "    relu_golden_output_sfixed = [0] * len(relu_input_sfixed)\n",
        "    for i in range(len(relu_input_sfixed)):\n",
        "        if relu_input_sfixed[i] < 0:\n",
        "            relu_golden_output_sfixed[i] = 0\n",
        "        else:\n",
        "            relu_golden_output_sfixed[i] = relu_input_sfixed[i]\n",
        "\n",
        "    # Since all current inputs are positive, the output will be the same.\n",
        "    # We can also test with a mix of positive and negative inputs later if needed.\n",
        "\n",
        "    print(\"\\n--- Golden ReLU Output (relu_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    # E.g. golden_output[0] = 16'sd108;\n",
        "    print(\"logic signed [15:0] golden_relu_output [0:3]; // Or NUM_ELEMENTS-1\")\n",
        "    print(\"initial begin\")\n",
        "    for i in range(len(relu_golden_output_sfixed)):\n",
        "        approx_float = sfixed_to_float(relu_golden_output_sfixed[i])\n",
        "        print(f\"    golden_relu_output[{i}] = 16'sd{relu_golden_output_sfixed[i]}; \\t// Approx Float: {approx_float:.4f}\")\n",
        "    print(\"end\")\n",
        "\n",
        "    print(\"\\n--- For a more comprehensive ReLU test, consider these inputs: ---\")\n",
        "    mixed_inputs_float = [0.42, -0.1, 0.0, -0.99, 2.0] # Example mixed inputs\n",
        "    mixed_inputs_sfixed = [float_to_sfixed(f) for f in mixed_inputs_float]\n",
        "    mixed_outputs_sfixed = [max(0, s_val) if s_val >=0 else 0 for s_val in mixed_inputs_sfixed] # ReLU on sfixed\n",
        "\n",
        "    print(\"Example Mixed Inputs (sfixed):\", mixed_inputs_sfixed)\n",
        "    print(\"Example Mixed Outputs (sfixed):\", mixed_outputs_sfixed)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkibS994uUwB",
        "outputId": "9a2a368a-da9a-4b71-87d2-44b470121759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Golden Fixed-Point Values for ReLU Module ---\n",
            "Fixed-Point Config: TOTAL_BITS=16, FRACTIONAL_BITS=8 (S8.8), SCALE=256\n",
            "\n",
            "--- Input to ReLU Module (relu_input_sfixed) ---\n",
            "--- (These are the actual outputs from the Verilog fc_layer) ---\n",
            "i_data[0] = 16'sd108; \t// Approx Float: 0.4219\n",
            "i_data[1] = 16'sd254; \t// Approx Float: 0.9922\n",
            "i_data[2] = 16'sd218; \t// Approx Float: 0.8516\n",
            "i_data[3] = 16'sd186; \t// Approx Float: 0.7266\n",
            "\n",
            "--- Golden ReLU Output (relu_golden_output_sfixed) for Verilog Testbench ---\n",
            "logic signed [15:0] golden_relu_output [0:3]; // Or NUM_ELEMENTS-1\n",
            "initial begin\n",
            "    golden_relu_output[0] = 16'sd108; \t// Approx Float: 0.4219\n",
            "    golden_relu_output[1] = 16'sd254; \t// Approx Float: 0.9922\n",
            "    golden_relu_output[2] = 16'sd218; \t// Approx Float: 0.8516\n",
            "    golden_relu_output[3] = 16'sd186; \t// Approx Float: 0.7266\n",
            "end\n",
            "\n",
            "--- For a more comprehensive ReLU test, consider these inputs: ---\n",
            "Example Mixed Inputs (sfixed): [108, -26, 0, -253, 512]\n",
            "Example Mixed Outputs (sfixed): [108, 0, 0, 0, 512]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONV1D GOLDEN OUTPUT"
      ],
      "metadata": {
        "id": "ip2aNnMV8ZNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1\n",
        "\n",
        "def float_to_sfixed(val_float, f_bits=FRACTIONAL_BITS, total_bits=TOTAL_BITS):\n",
        "    scale_factor = 1 << f_bits\n",
        "    min_val = -(1 << (total_bits - 1))\n",
        "    max_val = (1 << (total_bits - 1)) - 1\n",
        "    scaled_val = int(round(val_float * scale_factor))\n",
        "    clamped_val = max(min_val, min(max_val, scaled_val))\n",
        "    return clamped_val\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- Conv1 Parameters ---\n",
        "NUM_IN_CHANNELS_CONV1 = 4\n",
        "NUM_OUT_CHANNELS_CONV1 = 2\n",
        "KERNEL_SIZE_CONV1 = 3\n",
        "STRIDE_CONV1 = 1\n",
        "PADDING_CONV1 = 1\n",
        "NUM_IN_FRAMES_CONV1 = 2 # Output frames from Upsampler1\n",
        "\n",
        "# --- Helper function for fixed-point Conv1D (bit-accurate) ---\n",
        "def conv1d_fixed_point_manual(input_data_sfixed, # Shape: [NUM_IN_CHANNELS][NUM_IN_FRAMES]\n",
        "                              kernels_sfixed,    # Shape: [NUM_OUT_CHANNELS][NUM_IN_CHANNELS][KERNEL_SIZE]\n",
        "                              biases_sfixed,     # Shape: [NUM_OUT_CHANNELS]\n",
        "                              padding, stride, kernel_size,\n",
        "                              f_bits=FRACTIONAL_BITS, total_bits=TOTAL_BITS):\n",
        "\n",
        "    num_in_ch = len(input_data_sfixed)\n",
        "    num_in_fr = len(input_data_sfixed[0])\n",
        "    num_out_ch = len(kernels_sfixed)\n",
        "\n",
        "    scale = 1 << f_bits\n",
        "    round_const_product = 1 << (f_bits - 1) if f_bits > 0 else 0 # For product (S.2F -> S.F)\n",
        "\n",
        "    s_max = (1 << (total_bits - 1)) - 1\n",
        "    s_min = -(1 << (total_bits - 1))\n",
        "\n",
        "    def _saturate(value):\n",
        "        return max(s_min, min(s_max, value))\n",
        "\n",
        "    # Apply padding\n",
        "    padded_input_sfixed = []\n",
        "    for ch_data in input_data_sfixed:\n",
        "        padded_ch_data = [0] * padding + ch_data + [0] * padding\n",
        "        padded_input_sfixed.append(padded_ch_data)\n",
        "\n",
        "    num_in_fr_padded = num_in_fr + 2 * padding\n",
        "    num_out_fr = math.floor((num_in_fr_padded - kernel_size) / stride + 1)\n",
        "\n",
        "    output_data_sfixed = [[0] * num_out_fr for _ in range(num_out_ch)]\n",
        "\n",
        "    for oc in range(num_out_ch): # Output Channel\n",
        "        for f_out_idx in range(num_out_fr): # Output Frame\n",
        "            receptive_field_start = f_out_idx * stride\n",
        "\n",
        "            # This will store sum of terms already scaled to S.F (like in fc_layer)\n",
        "            current_sum_s_dot_f = 0\n",
        "\n",
        "            for ic in range(num_in_ch): # Input Channel\n",
        "                for k_idx in range(kernel_size): # Kernel Tap\n",
        "                    input_val_idx = receptive_field_start + k_idx\n",
        "\n",
        "                    input_val_sfixed = padded_input_sfixed[ic][input_val_idx]\n",
        "                    kernel_val_sfixed = kernels_sfixed[oc][ic][k_idx]\n",
        "\n",
        "                    # S.F * S.F = S.2F (product is scaled by SCALE*SCALE)\n",
        "                    product_s_dot_2f = input_val_sfixed * kernel_val_sfixed\n",
        "\n",
        "                    # Round and scale back to S.F (scaled by SCALE)\n",
        "                    if product_s_dot_2f >= 0:\n",
        "                        scaled_product_s_dot_f = (product_s_dot_2f + round_const_product) // scale\n",
        "                    else:\n",
        "                        scaled_product_s_dot_f = (product_s_dot_2f + round_const_product) // scale\n",
        "                        # Note: Python's // is floor division. For negative, (val + 0.5) // 1 can differ from strict arithmetic shift with rounding.\n",
        "                        # Verilog: (product_wide + ROUND_CONST) >>> FRACTIONAL_BITS.\n",
        "                        # This Python code mimics the Verilog's simple positive rounding for now.\n",
        "\n",
        "                    current_sum_s_dot_f += scaled_product_s_dot_f\n",
        "\n",
        "            # Add bias (which is already S.F)\n",
        "            final_value_s_dot_f = current_sum_s_dot_f + biases_sfixed[oc]\n",
        "            output_data_sfixed[oc][f_out_idx] = _saturate(final_value_s_dot_f)\n",
        "\n",
        "    return output_data_sfixed\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Bit-Accurate Golden Values for Conv1 Layer ---\")\n",
        "\n",
        "    # 1. Input to Conv1 (output of previous Upsample stage)\n",
        "    # Represents 4 channels, 2 frames each: [[108, 108], [254, 254], [218, 218], [186, 186]]\n",
        "    conv1_input_sfixed = [\n",
        "        [108, 108], # Channel 0\n",
        "        [254, 254], # Channel 1\n",
        "        [218, 218], # Channel 2\n",
        "        [186, 186]  # Channel 3\n",
        "    ]\n",
        "    print(\"\\n--- Input to Conv1 Module (conv1_input_sfixed) ---\")\n",
        "    print(\"--- (4 channels, 2 frames each) ---\")\n",
        "    for ch in range(len(conv1_input_sfixed)):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in conv1_input_sfixed[ch]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in conv1_input_sfixed[ch]]\n",
        "        print(f\"Input Channel {ch}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n",
        "\n",
        "    # 2. Define Conv1 Weights and Biases (float, from SimpleDecoder architecture)\n",
        "    kernels_conv1_float = [ # Shape: [out_ch=2][in_ch=4][k_size=3]\n",
        "        # out_channel 0\n",
        "        [   # in_channel 0\n",
        "            [0.1, 0.2, 0.1], # k1, k2, k3\n",
        "            # in_channel 1\n",
        "            [0.3, 0.1, 0.2],\n",
        "            # in_channel 2\n",
        "            [0.2, 0.3, 0.1],\n",
        "            # in_channel 3\n",
        "            [0.1, 0.1, 0.3]\n",
        "        ],\n",
        "        # out_channel 1\n",
        "        [   # in_channel 0\n",
        "            [0.4, 0.2, 0.1],\n",
        "            # in_channel 1\n",
        "            [0.1, 0.3, 0.4],\n",
        "            # in_channel 2\n",
        "            [0.3, 0.2, 0.2],\n",
        "            # in_channel 3\n",
        "            [0.2, 0.4, 0.1]\n",
        "        ]\n",
        "    ]\n",
        "    biases_conv1_float = [0.05, 0.06]\n",
        "\n",
        "    # 3. Convert Conv1 Weights and Biases to fixed-point\n",
        "    kernels_conv1_sfixed = [\n",
        "        [[float_to_sfixed(val) for val in tap_list] for tap_list in ch_list] for ch_list in kernels_conv1_float\n",
        "    ]\n",
        "    biases_conv1_sfixed = [float_to_sfixed(val) for val in biases_conv1_float]\n",
        "\n",
        "    print(\"\\n--- Conv1 Kernels (kernels_conv1_sfixed) ---\")\n",
        "    # Format for Verilog parameters/locals or testbench\n",
        "    for oc in range(NUM_OUT_CHANNELS_CONV1):\n",
        "        print(f\"// Kernel for Output Channel {oc}\")\n",
        "        for ic in range(NUM_IN_CHANNELS_CONV1):\n",
        "            tap_str = \", \".join([f\"16'sd{kernels_conv1_sfixed[oc][ic][k]}\" for k in range(KERNEL_SIZE_CONV1)])\n",
        "            print(f\"  // InCh {ic}: {{{tap_str}}}\")\n",
        "\n",
        "    print(\"\\n--- Conv1 Biases (biases_conv1_sfixed) ---\")\n",
        "    bias_str = \", \".join([f\"16'sd{biases_conv1_sfixed[oc]}\" for oc in range(NUM_OUT_CHANNELS_CONV1)])\n",
        "    print(f\"{{ {bias_str} }}\")\n",
        "\n",
        "\n",
        "    # 4. Calculate Golden Output using the fixed-point Conv1D function\n",
        "    conv1_golden_output_sfixed = conv1d_fixed_point_manual(\n",
        "        input_data_sfixed=conv1_input_sfixed,\n",
        "        kernels_sfixed=kernels_conv1_sfixed,\n",
        "        biases_sfixed=biases_conv1_sfixed,\n",
        "        padding=PADDING_CONV1,\n",
        "        stride=STRIDE_CONV1,\n",
        "        kernel_size=KERNEL_SIZE_CONV1\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Golden Conv1 Output (conv1_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    print(f\"--- ({NUM_OUT_CHANNELS_CONV1} channels, {len(conv1_golden_output_sfixed[0])} frames each) ---\")\n",
        "    for oc in range(len(conv1_golden_output_sfixed)):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in conv1_golden_output_sfixed[oc]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in conv1_golden_output_sfixed[oc]]\n",
        "        print(f\"Output Channel {oc}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyr0Uq_s3rId",
        "outputId": "79a2a923-c7a8-4524-b2fa-428cb1722e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Bit-Accurate Golden Values for Conv1 Layer ---\n",
            "\n",
            "--- Input to Conv1 Module (conv1_input_sfixed) ---\n",
            "--- (4 channels, 2 frames each) ---\n",
            "Input Channel 0: [16'sd108, 16'sd108]; \t// Approx Floats: [0.4219, 0.4219]\n",
            "Input Channel 1: [16'sd254, 16'sd254]; \t// Approx Floats: [0.9922, 0.9922]\n",
            "Input Channel 2: [16'sd218, 16'sd218]; \t// Approx Floats: [0.8516, 0.8516]\n",
            "Input Channel 3: [16'sd186, 16'sd186]; \t// Approx Floats: [0.7266, 0.7266]\n",
            "\n",
            "--- Conv1 Kernels (kernels_conv1_sfixed) ---\n",
            "// Kernel for Output Channel 0\n",
            "  // InCh 0: {16'sd26, 16'sd51, 16'sd26}\n",
            "  // InCh 1: {16'sd77, 16'sd26, 16'sd51}\n",
            "  // InCh 2: {16'sd51, 16'sd77, 16'sd26}\n",
            "  // InCh 3: {16'sd26, 16'sd26, 16'sd77}\n",
            "// Kernel for Output Channel 1\n",
            "  // InCh 0: {16'sd102, 16'sd51, 16'sd26}\n",
            "  // InCh 1: {16'sd26, 16'sd77, 16'sd102}\n",
            "  // InCh 2: {16'sd77, 16'sd51, 16'sd51}\n",
            "  // InCh 3: {16'sd51, 16'sd102, 16'sd26}\n",
            "\n",
            "--- Conv1 Biases (biases_conv1_sfixed) ---\n",
            "{ 16'sd13, 16'sd15 }\n",
            "\n",
            "--- Golden Conv1 Output (conv1_golden_output_sfixed) for Verilog Testbench ---\n",
            "--- (2 channels, 2 frames each) ---\n",
            "Output Channel 0: [16'sd286, 16'sd295]; \t// Approx Floats: [1.1172, 1.1523]\n",
            "Output Channel 1: [16'sd404, 16'sd402]; \t// Approx Floats: [1.5781, 1.5703]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RELU 2 GOLDEN OUTPUT"
      ],
      "metadata": {
        "id": "As-VJDN3_PRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # For round\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a scaled signed integer back to a float.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- ReLU (2nd Instance) Golden Value Generation ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Golden Fixed-Point Values for 2nd ReLU Module ---\")\n",
        "    print(f\"--- Input is the output of Conv1 ---\")\n",
        "    print(f\"Fixed-Point Config: TOTAL_BITS={TOTAL_BITS}, FRACTIONAL_BITS={FRACTIONAL_BITS} (S{INTEGER_BITS+1}.{FRACTIONAL_BITS}), SCALE={SCALE}\\n\")\n",
        "\n",
        "    # 1. Define Inputs for the 2nd ReLU stage\n",
        "    # These are the fixed-point integer outputs from the Verilog conv1_module simulation.\n",
        "    # conv1_module output was: [[286, 295], [404, 402]]\n",
        "    relu2_input_sfixed = [\n",
        "        [286, 295], # Channel 0\n",
        "        [404, 402]  # Channel 1\n",
        "    ]\n",
        "    num_channels_relu2 = 2\n",
        "    num_frames_relu2 = 2\n",
        "\n",
        "    print(\"--- Input to 2nd ReLU Module (relu2_input_sfixed) ---\")\n",
        "    print(f\"--- ({num_channels_relu2} channels, {num_frames_relu2} frames each) ---\")\n",
        "    for ch in range(num_channels_relu2):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in relu2_input_sfixed[ch]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in relu2_input_sfixed[ch]]\n",
        "        print(f\"Input Channel {ch}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n",
        "    # 2. Calculate Golden Output for ReLU\n",
        "    relu2_golden_output_sfixed = [[0]*num_frames_relu2 for _ in range(num_channels_relu2)]\n",
        "    for ch in range(num_channels_relu2):\n",
        "        for fr in range(num_frames_relu2):\n",
        "            input_val = relu2_input_sfixed[ch][fr]\n",
        "            if input_val < 0:\n",
        "                relu2_golden_output_sfixed[ch][fr] = 0\n",
        "            else:\n",
        "                relu2_golden_output_sfixed[ch][fr] = input_val\n",
        "\n",
        "    print(\"\\n--- Golden Output for 2nd ReLU (relu2_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    print(f\"--- ({num_channels_relu2} channels, {num_frames_relu2} frames each) ---\")\n",
        "    print(f\"logic signed [15:0] golden_relu2_output [0:{num_channels_relu2-1}][0:{num_frames_relu2-1}];\")\n",
        "    print(\"initial begin\")\n",
        "    for ch in range(num_channels_relu2):\n",
        "        for fr in range(num_frames_relu2):\n",
        "            val = relu2_golden_output_sfixed[ch][fr]\n",
        "            approx_float = sfixed_to_float(val)\n",
        "            print(f\"    golden_relu2_output[{ch}][{fr}] = 16'sd{val}; \\t// Approx Float: {approx_float:.4f}\")\n",
        "    print(\"end\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ZfraNi6POP",
        "outputId": "43351d8d-021d-4f61-b161-382c688cab0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Golden Fixed-Point Values for 2nd ReLU Module ---\n",
            "--- Input is the output of Conv1 ---\n",
            "Fixed-Point Config: TOTAL_BITS=16, FRACTIONAL_BITS=8 (S8.8), SCALE=256\n",
            "\n",
            "--- Input to 2nd ReLU Module (relu2_input_sfixed) ---\n",
            "--- (2 channels, 2 frames each) ---\n",
            "Input Channel 0: [16'sd286, 16'sd295]; \t// Approx Floats: [1.1172, 1.1523]\n",
            "Input Channel 1: [16'sd404, 16'sd402]; \t// Approx Floats: [1.5781, 1.5703]\n",
            "\n",
            "--- Golden Output for 2nd ReLU (relu2_golden_output_sfixed) for Verilog Testbench ---\n",
            "--- (2 channels, 2 frames each) ---\n",
            "logic signed [15:0] golden_relu2_output [0:1][0:1];\n",
            "initial begin\n",
            "    golden_relu2_output[0][0] = 16'sd286; \t// Approx Float: 1.1172\n",
            "    golden_relu2_output[0][1] = 16'sd295; \t// Approx Float: 1.1523\n",
            "    golden_relu2_output[1][0] = 16'sd404; \t// Approx Float: 1.5781\n",
            "    golden_relu2_output[1][1] = 16'sd402; \t// Approx Float: 1.5703\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UPSAMPLE 2 GOLDEN OUTPUT"
      ],
      "metadata": {
        "id": "yv7XcTU3AJIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # For round\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a scaled signed integer back to a float.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- Upsample (2nd Instance) Golden Value Generation ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Golden Fixed-Point Values for 2nd Upsample Module (scale_factor=2) ---\")\n",
        "    print(f\"--- Input is the output of the 2nd ReLU stage (after Conv1) ---\")\n",
        "    print(f\"Fixed-Point Config: TOTAL_BITS={TOTAL_BITS}, FRACTIONAL_BITS={FRACTIONAL_BITS} (S{INTEGER_BITS+1}.{FRACTIONAL_BITS}), SCALE={SCALE}\\n\")\n",
        "\n",
        "    # 1. Define Inputs for the 2nd Upsample stage\n",
        "    # These are the fixed-point integer outputs from the 2nd ReLU stage.\n",
        "    # Output of 2nd ReLU was: [[286, 295], [404, 402]]\n",
        "    upsample2_input_sfixed = [\n",
        "        [286, 295], # Channel 0 (2 frames)\n",
        "        [404, 402]  # Channel 1 (2 frames)\n",
        "    ]\n",
        "    num_channels_upsample2 = 2\n",
        "    input_frames_per_channel_upsample2 = 2\n",
        "    scale_factor = 2\n",
        "    output_frames_per_channel_upsample2 = input_frames_per_channel_upsample2 * scale_factor # Should be 4\n",
        "\n",
        "    print(\"--- Input to 2nd Upsample Module (upsample2_input_sfixed) ---\")\n",
        "    print(f\"--- ({num_channels_upsample2} channels, {input_frames_per_channel_upsample2} frames each) ---\")\n",
        "    for ch in range(num_channels_upsample2):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in upsample2_input_sfixed[ch]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in upsample2_input_sfixed[ch]]\n",
        "        print(f\"Input Channel {ch}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n",
        "    # 2. Calculate Golden Output for Upsample\n",
        "    upsample2_golden_output_sfixed = [[0]*output_frames_per_channel_upsample2 for _ in range(num_channels_upsample2)]\n",
        "\n",
        "    for ch in range(num_channels_upsample2):\n",
        "        for out_fr_idx in range(output_frames_per_channel_upsample2):\n",
        "            # Nearest neighbor: replicate the input value\n",
        "            # Each input frame is repeated 'scale_factor' times\n",
        "            in_fr_idx = out_fr_idx // scale_factor\n",
        "            upsample2_golden_output_sfixed[ch][out_fr_idx] = upsample2_input_sfixed[ch][in_fr_idx]\n",
        "\n",
        "    print(\"\\n--- Golden Output for 2nd Upsample (upsample2_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    print(f\"--- ({num_channels_upsample2} channels, {output_frames_per_channel_upsample2} frames each) ---\")\n",
        "    print(f\"logic signed [15:0] golden_upsample2_output [0:{num_channels_upsample2-1}][0:{output_frames_per_channel_upsample2-1}];\")\n",
        "    print(\"initial begin\")\n",
        "    for ch in range(num_channels_upsample2):\n",
        "        for fr in range(output_frames_per_channel_upsample2):\n",
        "            val = upsample2_golden_output_sfixed[ch][fr]\n",
        "            approx_float = sfixed_to_float(val)\n",
        "            print(f\"    golden_upsample2_output[{ch}][{fr}] = 16'sd{val}; \\t// Approx Float: {approx_float:.4f}\")\n",
        "    print(\"end\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO9YJOyx_Vz1",
        "outputId": "e853ad82-544e-4ff6-e1ae-f6cad1149d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Golden Fixed-Point Values for 2nd Upsample Module (scale_factor=2) ---\n",
            "--- Input is the output of the 2nd ReLU stage (after Conv1) ---\n",
            "Fixed-Point Config: TOTAL_BITS=16, FRACTIONAL_BITS=8 (S8.8), SCALE=256\n",
            "\n",
            "--- Input to 2nd Upsample Module (upsample2_input_sfixed) ---\n",
            "--- (2 channels, 2 frames each) ---\n",
            "Input Channel 0: [16'sd286, 16'sd295]; \t// Approx Floats: [1.1172, 1.1523]\n",
            "Input Channel 1: [16'sd404, 16'sd402]; \t// Approx Floats: [1.5781, 1.5703]\n",
            "\n",
            "--- Golden Output for 2nd Upsample (upsample2_golden_output_sfixed) for Verilog Testbench ---\n",
            "--- (2 channels, 4 frames each) ---\n",
            "logic signed [15:0] golden_upsample2_output [0:1][0:3];\n",
            "initial begin\n",
            "    golden_upsample2_output[0][0] = 16'sd286; \t// Approx Float: 1.1172\n",
            "    golden_upsample2_output[0][1] = 16'sd286; \t// Approx Float: 1.1172\n",
            "    golden_upsample2_output[0][2] = 16'sd295; \t// Approx Float: 1.1523\n",
            "    golden_upsample2_output[0][3] = 16'sd295; \t// Approx Float: 1.1523\n",
            "    golden_upsample2_output[1][0] = 16'sd404; \t// Approx Float: 1.5781\n",
            "    golden_upsample2_output[1][1] = 16'sd404; \t// Approx Float: 1.5781\n",
            "    golden_upsample2_output[1][2] = 16'sd402; \t// Approx Float: 1.5703\n",
            "    golden_upsample2_output[1][3] = 16'sd402; \t// Approx Float: 1.5703\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONV1D 2 GOLDEN OUTPUT"
      ],
      "metadata": {
        "id": "WgYIY5xIByX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1\n",
        "\n",
        "def float_to_sfixed(val_float, f_bits=FRACTIONAL_BITS, total_bits=TOTAL_BITS):\n",
        "    scale_factor = 1 << f_bits\n",
        "    min_val = -(1 << (total_bits - 1))\n",
        "    max_val = (1 << (total_bits - 1)) - 1\n",
        "    scaled_val = int(round(val_float * scale_factor))\n",
        "    clamped_val = max(min_val, min(max_val, scaled_val))\n",
        "    return clamped_val\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- Conv1D Fixed-Point Manual Calculation Function (reused) ---\n",
        "def conv1d_fixed_point_manual(input_data_sfixed, # Shape: [NUM_IN_CHANNELS][NUM_IN_FRAMES]\n",
        "                              kernels_sfixed,    # Shape: [NUM_OUT_CHANNELS][NUM_IN_CHANNELS][KERNEL_SIZE]\n",
        "                              biases_sfixed,     # Shape: [NUM_OUT_CHANNELS]\n",
        "                              padding, stride, kernel_size,\n",
        "                              f_bits=FRACTIONAL_BITS, total_bits=TOTAL_BITS):\n",
        "\n",
        "    num_in_ch = len(input_data_sfixed)\n",
        "    num_in_fr = len(input_data_sfixed[0])\n",
        "    num_out_ch = len(kernels_sfixed)\n",
        "\n",
        "    scale = 1 << f_bits\n",
        "    round_const_product = 1 << (f_bits - 1) if f_bits > 0 else 0\n",
        "\n",
        "    s_max = (1 << (total_bits - 1)) - 1\n",
        "    s_min = -(1 << (total_bits - 1))\n",
        "\n",
        "    def _saturate(value):\n",
        "        return max(s_min, min(s_max, value))\n",
        "\n",
        "    padded_input_sfixed = []\n",
        "    for ch_data in input_data_sfixed:\n",
        "        padded_ch_data = [0] * padding + ch_data + [0] * padding\n",
        "        padded_input_sfixed.append(padded_ch_data)\n",
        "\n",
        "    num_in_fr_padded = num_in_fr + 2 * padding\n",
        "    num_out_fr = math.floor((num_in_fr_padded - kernel_size) / stride + 1)\n",
        "\n",
        "    output_data_sfixed = [[0] * num_out_fr for _ in range(num_out_ch)]\n",
        "\n",
        "    for oc in range(num_out_ch):\n",
        "        for f_out_idx in range(num_out_fr):\n",
        "            receptive_field_start = f_out_idx * stride\n",
        "            current_sum_s_dot_f = 0\n",
        "            for ic in range(num_in_ch):\n",
        "                for k_idx in range(kernel_size):\n",
        "                    input_val_idx = receptive_field_start + k_idx\n",
        "                    input_val_sfixed = padded_input_sfixed[ic][input_val_idx]\n",
        "                    kernel_val_sfixed = kernels_sfixed[oc][ic][k_idx]\n",
        "                    product_s_dot_2f = input_val_sfixed * kernel_val_sfixed\n",
        "                    if product_s_dot_2f >= 0:\n",
        "                        scaled_product_s_dot_f = (product_s_dot_2f + round_const_product) // scale\n",
        "                    else:\n",
        "                        scaled_product_s_dot_f = (product_s_dot_2f + round_const_product) // scale\n",
        "                    current_sum_s_dot_f += scaled_product_s_dot_f\n",
        "            final_value_s_dot_f = current_sum_s_dot_f + biases_sfixed[oc]\n",
        "            output_data_sfixed[oc][f_out_idx] = _saturate(final_value_s_dot_f)\n",
        "    return output_data_sfixed\n",
        "\n",
        "# --- Conv2 Parameters ---\n",
        "NUM_IN_CHANNELS_CONV2 = 2\n",
        "NUM_OUT_CHANNELS_CONV2 = 1\n",
        "KERNEL_SIZE_CONV2 = 3\n",
        "STRIDE_CONV2 = 1\n",
        "PADDING_CONV2 = 1\n",
        "NUM_IN_FRAMES_CONV2 = 4 # Output frames from Upsampler2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Bit-Accurate Golden Values for Conv2 Layer ---\")\n",
        "\n",
        "    # 1. Input to Conv2 (output of previous Upsample stage)\n",
        "    # Represents 2 channels, 4 frames each\n",
        "    conv2_input_sfixed = [\n",
        "        [286, 286, 295, 295], # Channel 0 from Upsample2\n",
        "        [404, 404, 402, 402]  # Channel 1 from Upsample2\n",
        "    ]\n",
        "    print(\"\\n--- Input to Conv2 Module (conv2_input_sfixed) ---\")\n",
        "    print(\"--- (2 channels, 4 frames each) ---\")\n",
        "    for ch in range(len(conv2_input_sfixed)):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in conv2_input_sfixed[ch]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in conv2_input_sfixed[ch]]\n",
        "        print(f\"Input Channel {ch}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n",
        "    # 2. Define Conv2 Weights and Biases (float, from SimpleDecoder architecture)\n",
        "    # kernels_conv2_float: [out_ch=1][in_ch=2][k_size=3]\n",
        "    kernels_conv2_float = [\n",
        "        # out_channel 0\n",
        "        [   # in_channel 0\n",
        "            [0.5, 0.1, 0.2],\n",
        "            # in_channel 1\n",
        "            [0.2, 0.3, 0.5]\n",
        "        ]\n",
        "    ]\n",
        "    biases_conv2_float = [0.07] # Single bias for the single output channel\n",
        "\n",
        "    # 3. Convert Conv2 Weights and Biases to fixed-point\n",
        "    kernels_conv2_sfixed = [\n",
        "        [[float_to_sfixed(val) for val in tap_list] for tap_list in ch_list] for ch_list in kernels_conv2_float\n",
        "    ]\n",
        "    biases_conv2_sfixed = [float_to_sfixed(val) for val in biases_conv2_float]\n",
        "\n",
        "    print(\"\\n--- Conv2 Kernels (kernels_conv2_sfixed) ---\")\n",
        "    for oc in range(NUM_OUT_CHANNELS_CONV2):\n",
        "        print(f\"// Kernel for Output Channel {oc}\")\n",
        "        for ic in range(NUM_IN_CHANNELS_CONV2):\n",
        "            tap_str = \", \".join([f\"16'sd{kernels_conv2_sfixed[oc][ic][k]}\" for k in range(KERNEL_SIZE_CONV2)])\n",
        "            print(f\"  // InCh {ic}: {{{tap_str}}}\")\n",
        "\n",
        "    print(\"\\n--- Conv2 Biases (biases_conv2_sfixed) ---\")\n",
        "    bias_str = \", \".join([f\"16'sd{biases_conv2_sfixed[oc]}\" for oc in range(NUM_OUT_CHANNELS_CONV2)])\n",
        "    print(f\"{{ {bias_str} }}\")\n",
        "\n",
        "    # 4. Calculate Golden Output using the fixed-point Conv1D function\n",
        "    conv2_golden_output_sfixed = conv1d_fixed_point_manual(\n",
        "        input_data_sfixed=conv2_input_sfixed,\n",
        "        kernels_sfixed=kernels_conv2_sfixed,\n",
        "        biases_sfixed=biases_conv2_sfixed,\n",
        "        padding=PADDING_CONV2,\n",
        "        stride=STRIDE_CONV2,\n",
        "        kernel_size=KERNEL_SIZE_CONV2\n",
        "    )\n",
        "\n",
        "    # Expected output shape: 1 channel, 4 frames\n",
        "    num_out_fr_conv2 = math.floor(((NUM_IN_FRAMES_CONV2 + 2 * PADDING_CONV2) - KERNEL_SIZE_CONV2) / STRIDE_CONV2 + 1)\n",
        "\n",
        "    print(\"\\n--- Golden Conv2 Output (conv2_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    print(f\"--- ({NUM_OUT_CHANNELS_CONV2} channel, {num_out_fr_conv2} frames each) ---\")\n",
        "    for oc in range(len(conv2_golden_output_sfixed)): # Should be 1 output channel\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in conv2_golden_output_sfixed[oc]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in conv2_golden_output_sfixed[oc]]\n",
        "        print(f\"Output Channel {oc}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-PNa-OHBxlF",
        "outputId": "ef5faf60-1290-4cc8-bd50-7d3f823995b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Bit-Accurate Golden Values for Conv2 Layer ---\n",
            "\n",
            "--- Input to Conv2 Module (conv2_input_sfixed) ---\n",
            "--- (2 channels, 4 frames each) ---\n",
            "Input Channel 0: [16'sd286, 16'sd286, 16'sd295, 16'sd295]; \t// Approx Floats: [1.1172, 1.1172, 1.1523, 1.1523]\n",
            "Input Channel 1: [16'sd404, 16'sd404, 16'sd402, 16'sd402]; \t// Approx Floats: [1.5781, 1.5781, 1.5703, 1.5703]\n",
            "\n",
            "--- Conv2 Kernels (kernels_conv2_sfixed) ---\n",
            "// Kernel for Output Channel 0\n",
            "  // InCh 0: {16'sd128, 16'sd26, 16'sd51}\n",
            "  // InCh 1: {16'sd51, 16'sd77, 16'sd128}\n",
            "\n",
            "--- Conv2 Biases (biases_conv2_sfixed) ---\n",
            "{ 16'sd18 }\n",
            "\n",
            "--- Golden Conv2 Output (conv2_golden_output_sfixed) for Verilog Testbench ---\n",
            "--- (1 channel, 4 frames each) ---\n",
            "Output Channel 0: [16'sd428, 16'sd652, 16'sd652, 16'sd397]; \t// Approx Floats: [1.6719, 2.5469, 2.5469, 1.5508]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RELU 3 GOLDEN OUTPUT\n"
      ],
      "metadata": {
        "id": "Dq3beSgoEi1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # For round\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a scaled signed integer back to a float.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- ReLU (3rd Instance) Golden Value Generation ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Golden Fixed-Point Values for 3rd ReLU Module ---\")\n",
        "    print(f\"--- Input is the output of Conv2 ---\")\n",
        "    print(f\"Fixed-Point Config: TOTAL_BITS={TOTAL_BITS}, FRACTIONAL_BITS={FRACTIONAL_BITS} (S{INTEGER_BITS+1}.{FRACTIONAL_BITS}), SCALE={SCALE}\\n\")\n",
        "\n",
        "    # 1. Define Inputs for the 3rd ReLU stage\n",
        "    # These are the fixed-point integer outputs from the Verilog conv2_module simulation.\n",
        "    # conv2_module output was: [[428, 652, 652, 397]]\n",
        "    relu3_input_sfixed = [ # This is a list of lists: [NUM_CHANNELS][FRAMES_PER_CHANNEL]\n",
        "        [428, 652, 652, 397] # Channel 0 (4 frames)\n",
        "    ]\n",
        "    num_channels_relu3 = 1\n",
        "    num_frames_relu3 = 4 # Frames per channel\n",
        "\n",
        "    print(\"--- Input to 3rd ReLU Module (relu3_input_sfixed) ---\")\n",
        "    print(f\"--- ({num_channels_relu3} channel, {num_frames_relu3} frames each) ---\")\n",
        "    for ch in range(num_channels_relu3):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in relu3_input_sfixed[ch]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in relu3_input_sfixed[ch]]\n",
        "        print(f\"Input Channel {ch}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n",
        "    # 2. Calculate Golden Output for ReLU\n",
        "    relu3_golden_output_sfixed = [[0]*num_frames_relu3 for _ in range(num_channels_relu3)]\n",
        "    for ch in range(num_channels_relu3):\n",
        "        for fr in range(num_frames_relu3):\n",
        "            input_val = relu3_input_sfixed[ch][fr]\n",
        "            if input_val < 0:\n",
        "                relu3_golden_output_sfixed[ch][fr] = 0\n",
        "            else:\n",
        "                relu3_golden_output_sfixed[ch][fr] = input_val\n",
        "\n",
        "    print(\"\\n--- Golden Output for 3rd ReLU (relu3_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    print(f\"--- ({num_channels_relu3} channel, {num_frames_relu3} frames each) ---\")\n",
        "    print(f\"logic signed [15:0] golden_relu3_output [0:{num_channels_relu3-1}][0:{num_frames_relu3-1}];\")\n",
        "    print(\"initial begin\")\n",
        "    for ch in range(num_channels_relu3):\n",
        "        for fr in range(num_frames_relu3):\n",
        "            val = relu3_golden_output_sfixed[ch][fr]\n",
        "            approx_float = sfixed_to_float(val)\n",
        "            print(f\"    golden_relu3_output[{ch}][{fr}] = 16'sd{val}; \\t// Approx Float: {approx_float:.4f}\")\n",
        "    print(\"end\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLRMre6CANv7",
        "outputId": "2bb6bda2-6968-4e2c-e6e3-84053241f631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Golden Fixed-Point Values for 3rd ReLU Module ---\n",
            "--- Input is the output of Conv2 ---\n",
            "Fixed-Point Config: TOTAL_BITS=16, FRACTIONAL_BITS=8 (S8.8), SCALE=256\n",
            "\n",
            "--- Input to 3rd ReLU Module (relu3_input_sfixed) ---\n",
            "--- (1 channel, 4 frames each) ---\n",
            "Input Channel 0: [16'sd428, 16'sd652, 16'sd652, 16'sd397]; \t// Approx Floats: [1.6719, 2.5469, 2.5469, 1.5508]\n",
            "\n",
            "--- Golden Output for 3rd ReLU (relu3_golden_output_sfixed) for Verilog Testbench ---\n",
            "--- (1 channel, 4 frames each) ---\n",
            "logic signed [15:0] golden_relu3_output [0:0][0:3];\n",
            "initial begin\n",
            "    golden_relu3_output[0][0] = 16'sd428; \t// Approx Float: 1.6719\n",
            "    golden_relu3_output[0][1] = 16'sd652; \t// Approx Float: 2.5469\n",
            "    golden_relu3_output[0][2] = 16'sd652; \t// Approx Float: 2.5469\n",
            "    golden_relu3_output[0][3] = 16'sd397; \t// Approx Float: 1.5508\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv3 GOlden Oujtput"
      ],
      "metadata": {
        "id": "OZ4R5-chFTYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1\n",
        "\n",
        "def float_to_sfixed(val_float, f_bits=FRACTIONAL_BITS, total_bits=TOTAL_BITS):\n",
        "    scale_factor = 1 << f_bits\n",
        "    min_val = -(1 << (total_bits - 1))\n",
        "    max_val = (1 << (total_bits - 1)) - 1\n",
        "    scaled_val = int(round(val_float * scale_factor))\n",
        "    clamped_val = max(min_val, min(max_val, scaled_val))\n",
        "    return clamped_val\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- Conv1D Fixed-Point Manual Calculation Function (reused) ---\n",
        "def conv1d_fixed_point_manual(input_data_sfixed, # Shape: [NUM_IN_CHANNELS][NUM_IN_FRAMES]\n",
        "                              kernels_sfixed,    # Shape: [NUM_OUT_CHANNELS][NUM_IN_CHANNELS][KERNEL_SIZE]\n",
        "                              biases_sfixed,     # Shape: [NUM_OUT_CHANNELS]\n",
        "                              padding, stride, kernel_size,\n",
        "                              f_bits=FRACTIONAL_BITS, total_bits=TOTAL_BITS):\n",
        "\n",
        "    num_in_ch = len(input_data_sfixed)\n",
        "    num_in_fr = len(input_data_sfixed[0]) if num_in_ch > 0 else 0 # Handle empty input_data_sfixed\n",
        "    num_out_ch = len(kernels_sfixed)\n",
        "\n",
        "    scale = 1 << f_bits\n",
        "    round_const_product = 1 << (f_bits - 1) if f_bits > 0 else 0\n",
        "\n",
        "    s_max = (1 << (total_bits - 1)) - 1\n",
        "    s_min = -(1 << (total_bits - 1))\n",
        "\n",
        "    def _saturate(value):\n",
        "        return max(s_min, min(s_max, value))\n",
        "\n",
        "    padded_input_sfixed = []\n",
        "    if num_in_ch > 0:\n",
        "        for ch_data in input_data_sfixed:\n",
        "            padded_ch_data = [0] * padding + ch_data + [0] * padding\n",
        "            padded_input_sfixed.append(padded_ch_data)\n",
        "\n",
        "    num_in_fr_padded = num_in_fr + 2 * padding\n",
        "    if num_in_fr_padded < kernel_size : # check if kernel is larger than padded input\n",
        "        num_out_fr = 0\n",
        "    else:\n",
        "        num_out_fr = math.floor((num_in_fr_padded - kernel_size) / stride + 1)\n",
        "\n",
        "\n",
        "    output_data_sfixed = [[0] * num_out_fr for _ in range(num_out_ch)]\n",
        "\n",
        "    for oc in range(num_out_ch):\n",
        "        for f_out_idx in range(num_out_fr):\n",
        "            receptive_field_start = f_out_idx * stride\n",
        "            current_sum_s_dot_f = 0\n",
        "            for ic in range(num_in_ch):\n",
        "                for k_idx in range(kernel_size):\n",
        "                    input_val_idx = receptive_field_start + k_idx\n",
        "                    input_val_sfixed = padded_input_sfixed[ic][input_val_idx]\n",
        "                    kernel_val_sfixed = kernels_sfixed[oc][ic][k_idx]\n",
        "                    product_s_dot_2f = input_val_sfixed * kernel_val_sfixed\n",
        "                    if product_s_dot_2f >= 0:\n",
        "                        scaled_product_s_dot_f = (product_s_dot_2f + round_const_product) // scale\n",
        "                    else:\n",
        "                        scaled_product_s_dot_f = (product_s_dot_2f + round_const_product) // scale\n",
        "                    current_sum_s_dot_f += scaled_product_s_dot_f\n",
        "            final_value_s_dot_f = current_sum_s_dot_f + biases_sfixed[oc]\n",
        "            output_data_sfixed[oc][f_out_idx] = _saturate(final_value_s_dot_f)\n",
        "    return output_data_sfixed\n",
        "\n",
        "# --- Conv3_Output Parameters ---\n",
        "NUM_IN_CHANNELS_CONV3 = 1\n",
        "NUM_OUT_CHANNELS_CONV3 = 2 # N_MELS\n",
        "KERNEL_SIZE_CONV3 = 1\n",
        "STRIDE_CONV3 = 1\n",
        "PADDING_CONV3 = 0\n",
        "NUM_IN_FRAMES_CONV3 = 4 # Output frames from 3rd ReLU (after Conv2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Bit-Accurate Golden Values for Conv3_Output Layer ---\")\n",
        "\n",
        "    # 1. Input to Conv3 (output of previous 3rd ReLU stage)\n",
        "    # Represents 1 channel, 4 frames each\n",
        "    conv3_input_sfixed = [\n",
        "        [428, 652, 652, 397] # Channel 0 from 3rd ReLU\n",
        "    ]\n",
        "    print(\"\\n--- Input to Conv3_Output Module (conv3_input_sfixed) ---\")\n",
        "    print(\"--- (1 channel, 4 frames each) ---\")\n",
        "    for ch in range(len(conv3_input_sfixed)):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in conv3_input_sfixed[ch]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in conv3_input_sfixed[ch]]\n",
        "        print(f\"Input Channel {ch}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n",
        "    # 2. Define Conv3_Output Weights and Biases (float, from SimpleDecoder architecture)\n",
        "    # kernels_conv3_float: [out_ch=2][in_ch=1][k_size=1]\n",
        "    kernels_conv3_float = [\n",
        "        [[0.8]], # Output Channel 0, Input Channel 0, Tap 0\n",
        "        [[0.9]]  # Output Channel 1, Input Channel 0, Tap 0\n",
        "    ]\n",
        "    biases_conv3_float = [0.08, 0.09] # Two biases for the two output channels\n",
        "\n",
        "    # 3. Convert Conv3_Output Weights and Biases to fixed-point\n",
        "    kernels_conv3_sfixed = [\n",
        "        [[float_to_sfixed(val) for val in tap_list] for tap_list in ch_list] for ch_list in kernels_conv3_float\n",
        "    ]\n",
        "    biases_conv3_sfixed = [float_to_sfixed(val) for val in biases_conv3_float]\n",
        "\n",
        "    print(\"\\n--- Conv3_Output Kernels (kernels_conv3_sfixed) ---\")\n",
        "    for oc in range(NUM_OUT_CHANNELS_CONV3):\n",
        "        print(f\"// Kernel for Output Channel {oc}\")\n",
        "        for ic in range(NUM_IN_CHANNELS_CONV3): # Should be 1 input channel\n",
        "            tap_str = \", \".join([f\"16'sd{kernels_conv3_sfixed[oc][ic][k]}\" for k in range(KERNEL_SIZE_CONV3)])\n",
        "            print(f\"  // InCh {ic}: {{{tap_str}}}\")\n",
        "\n",
        "    print(\"\\n--- Conv3_Output Biases (biases_conv3_sfixed) ---\")\n",
        "    bias_str = \", \".join([f\"16'sd{biases_conv3_sfixed[oc]}\" for oc in range(NUM_OUT_CHANNELS_CONV3)])\n",
        "    print(f\"{{ {bias_str} }}\")\n",
        "\n",
        "    # 4. Calculate Golden Output using the fixed-point Conv1D function\n",
        "    conv3_golden_output_sfixed = conv1d_fixed_point_manual(\n",
        "        input_data_sfixed=conv3_input_sfixed,\n",
        "        kernels_sfixed=kernels_conv3_sfixed,\n",
        "        biases_sfixed=biases_conv3_sfixed,\n",
        "        padding=PADDING_CONV3,\n",
        "        stride=STRIDE_CONV3,\n",
        "        kernel_size=KERNEL_SIZE_CONV3\n",
        "    )\n",
        "\n",
        "    # Expected output shape: 2 channels, 4 frames\n",
        "    num_out_fr_conv3 = math.floor(((NUM_IN_FRAMES_CONV3 + 2 * PADDING_CONV3) - KERNEL_SIZE_CONV3) / STRIDE_CONV3 + 1)\n",
        "\n",
        "    print(\"\\n--- Golden Conv3_Output (conv3_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    print(f\"--- ({NUM_OUT_CHANNELS_CONV3} channels, {num_out_fr_conv3} frames each) ---\")\n",
        "    for oc in range(len(conv3_golden_output_sfixed)):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in conv3_golden_output_sfixed[oc]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in conv3_golden_output_sfixed[oc]]\n",
        "        print(f\"Output Channel {oc}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqRKfA-REems",
        "outputId": "f8bcc456-f478-4bdf-f324-e0876ec2e91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Bit-Accurate Golden Values for Conv3_Output Layer ---\n",
            "\n",
            "--- Input to Conv3_Output Module (conv3_input_sfixed) ---\n",
            "--- (1 channel, 4 frames each) ---\n",
            "Input Channel 0: [16'sd428, 16'sd652, 16'sd652, 16'sd397]; \t// Approx Floats: [1.6719, 2.5469, 2.5469, 1.5508]\n",
            "\n",
            "--- Conv3_Output Kernels (kernels_conv3_sfixed) ---\n",
            "// Kernel for Output Channel 0\n",
            "  // InCh 0: {16'sd205}\n",
            "// Kernel for Output Channel 1\n",
            "  // InCh 0: {16'sd230}\n",
            "\n",
            "--- Conv3_Output Biases (biases_conv3_sfixed) ---\n",
            "{ 16'sd20, 16'sd23 }\n",
            "\n",
            "--- Golden Conv3_Output (conv3_golden_output_sfixed) for Verilog Testbench ---\n",
            "--- (2 channels, 4 frames each) ---\n",
            "Output Channel 0: [16'sd363, 16'sd542, 16'sd542, 16'sd338]; \t// Approx Floats: [1.4180, 2.1172, 2.1172, 1.3203]\n",
            "Output Channel 1: [16'sd408, 16'sd609, 16'sd609, 16'sd380]; \t// Approx Floats: [1.5938, 2.3789, 2.3789, 1.4844]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RELU 4 GOLDEN OUTPUT"
      ],
      "metadata": {
        "id": "1TzC0i60Gpl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math # For round\n",
        "\n",
        "# --- Fixed-Point Parameters (consistent) ---\n",
        "FRACTIONAL_BITS = 8\n",
        "TOTAL_BITS = 16\n",
        "INTEGER_BITS = TOTAL_BITS - FRACTIONAL_BITS - 1\n",
        "SCALE = 1 << FRACTIONAL_BITS\n",
        "\n",
        "MIN_SFIXED_VAL = -(1 << (TOTAL_BITS - 1))\n",
        "MAX_SFIXED_VAL = (1 << (TOTAL_BITS - 1)) - 1\n",
        "\n",
        "def sfixed_to_float(val_sfixed, f_bits=FRACTIONAL_BITS):\n",
        "    \"\"\"Converts a scaled signed integer back to a float.\"\"\"\n",
        "    scale_factor = 1 << f_bits\n",
        "    return float(val_sfixed) / scale_factor\n",
        "\n",
        "# --- ReLU (4th Instance) Golden Value Generation ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Generating Golden Fixed-Point Values for 4th (Final) ReLU Module ---\")\n",
        "    print(f\"--- Input is the output of Conv3_Output ---\")\n",
        "    print(f\"Fixed-Point Config: TOTAL_BITS={TOTAL_BITS}, FRACTIONAL_BITS={FRACTIONAL_BITS} (S{INTEGER_BITS+1}.{FRACTIONAL_BITS}), SCALE={SCALE}\\n\")\n",
        "\n",
        "    # 1. Define Inputs for the 4th ReLU stage\n",
        "    # These are the fixed-point integer outputs from the Verilog conv3_output_module simulation.\n",
        "    # conv3_output_module output was:\n",
        "    # Channel 0: [363, 542, 542, 338]\n",
        "    # Channel 1: [408, 609, 609, 380]\n",
        "    relu4_input_sfixed = [\n",
        "        [363, 542, 542, 338], # Channel 0\n",
        "        [408, 609, 609, 380]  # Channel 1\n",
        "    ]\n",
        "    num_channels_relu4 = 2\n",
        "    num_frames_relu4 = 4 # Frames per channel\n",
        "\n",
        "    print(\"--- Input to 4th ReLU Module (relu4_input_sfixed) ---\")\n",
        "    print(f\"--- ({num_channels_relu4} channels, {num_frames_relu4} frames each) ---\")\n",
        "    for ch in range(num_channels_relu4):\n",
        "        row_sfixed_str = \", \".join([f\"16'sd{val}\" for val in relu4_input_sfixed[ch]])\n",
        "        approx_floats = [f\"{sfixed_to_float(val):.4f}\" for val in relu4_input_sfixed[ch]]\n",
        "        print(f\"Input Channel {ch}: [{row_sfixed_str}]; \\t// Approx Floats: [{', '.join(approx_floats)}]\")\n",
        "\n",
        "    # 2. Calculate Golden Output for ReLU\n",
        "    relu4_golden_output_sfixed = [[0]*num_frames_relu4 for _ in range(num_channels_relu4)]\n",
        "    for ch in range(num_channels_relu4):\n",
        "        for fr in range(num_frames_relu4):\n",
        "            input_val = relu4_input_sfixed[ch][fr]\n",
        "            if input_val < 0:\n",
        "                relu4_golden_output_sfixed[ch][fr] = 0\n",
        "            else:\n",
        "                relu4_golden_output_sfixed[ch][fr] = input_val\n",
        "\n",
        "    print(\"\\n--- Golden Output for 4th ReLU (relu4_golden_output_sfixed) for Verilog Testbench ---\")\n",
        "    print(f\"--- ({num_channels_relu4} channels, {num_frames_relu4} frames each) ---\")\n",
        "    print(f\"logic signed [15:0] golden_relu4_output [0:{num_channels_relu4-1}][0:{num_frames_relu4-1}];\")\n",
        "    print(\"initial begin\")\n",
        "    for ch in range(num_channels_relu4):\n",
        "        for fr in range(num_frames_relu4):\n",
        "            val = relu4_golden_output_sfixed[ch][fr]\n",
        "            approx_float = sfixed_to_float(val)\n",
        "            print(f\"    golden_relu4_output[{ch}][{fr}] = 16'sd{val}; \\t// Approx Float: {approx_float:.4f}\")\n",
        "    print(\"end\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jMdC7c4Gowu",
        "outputId": "7d3bbf9c-77f1-4e9a-affe-0ed91cfc140e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Golden Fixed-Point Values for 4th (Final) ReLU Module ---\n",
            "--- Input is the output of Conv3_Output ---\n",
            "Fixed-Point Config: TOTAL_BITS=16, FRACTIONAL_BITS=8 (S8.8), SCALE=256\n",
            "\n",
            "--- Input to 4th ReLU Module (relu4_input_sfixed) ---\n",
            "--- (2 channels, 4 frames each) ---\n",
            "Input Channel 0: [16'sd363, 16'sd542, 16'sd542, 16'sd338]; \t// Approx Floats: [1.4180, 2.1172, 2.1172, 1.3203]\n",
            "Input Channel 1: [16'sd408, 16'sd609, 16'sd609, 16'sd380]; \t// Approx Floats: [1.5938, 2.3789, 2.3789, 1.4844]\n",
            "\n",
            "--- Golden Output for 4th ReLU (relu4_golden_output_sfixed) for Verilog Testbench ---\n",
            "--- (2 channels, 4 frames each) ---\n",
            "logic signed [15:0] golden_relu4_output [0:1][0:3];\n",
            "initial begin\n",
            "    golden_relu4_output[0][0] = 16'sd363; \t// Approx Float: 1.4180\n",
            "    golden_relu4_output[0][1] = 16'sd542; \t// Approx Float: 2.1172\n",
            "    golden_relu4_output[0][2] = 16'sd542; \t// Approx Float: 2.1172\n",
            "    golden_relu4_output[0][3] = 16'sd338; \t// Approx Float: 1.3203\n",
            "    golden_relu4_output[1][0] = 16'sd408; \t// Approx Float: 1.5938\n",
            "    golden_relu4_output[1][1] = 16'sd609; \t// Approx Float: 2.3789\n",
            "    golden_relu4_output[1][2] = 16'sd609; \t// Approx Float: 2.3789\n",
            "    golden_relu4_output[1][3] = 16'sd380; \t// Approx Float: 1.4844\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qrp2Sl1FWLW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}